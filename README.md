## 1. Описание задачи и обоснование подхода.
**Цель проекта:** разработка модели компьютерного зрения для классификации изображений тарелок на две категории: «чистая» и «грязная».

**Задачи проекта:**
- Сформировать датасет изображений с тарелками.
- Преобразовать изображения для подачи в нейронную сеть.
- Разработать и обучить модель классификации изображений.
- Оценить качество модели на тестовой выборке.
- Визуализировать результаты и проанализировать ошибки.

**Обоснование выбора подхода:** Для решения задачи была выбрана модель на основе свёрточной нейронной сети (CNN), поскольку этот тип архитектур показывает отличные результаты при работе с изображениями. В качестве основы была взята предварительно обученная модель ResNet18, которая дообучалась на сформированном датасете. Это позволило значительно сократить время обучения и добиться допустимой точности на небольшом объеме данных.

## 2. Обоснование выбора методов, инструментов и архитектуры моделей
**Качество предобработки данных:**
- Изображения были приведены к размеру 224x224. На данном размере обучалась выбранная модель ResNet18.
- Применялась нормализация как в ImageNet по среднему и стандартному отклонению каналов (mean, std), соответствующая модели ResNet.
- Для обучения использовалась аугментация: случайные повороты, отражения и изменения яркости и резкости, что повысило обобщающую способность модели.
- Датасеты были переведены в тензоры.

**Разведывательный анализ:**
- Было проведено исследование баланса классов.
- Визуализированы примеры изображений для понимания различий между классами и применения аугментации.

## 3. Разработка модели и обучение
- Выбрана архитектура ResNet18 — классическая CNN, хорошо работающая с небольшими датасетами при использовании дообучения.
- Последний слой модели был заменён на выход с двумя нейронами, соответствующий бинарной классификации.
- Использовался CrossEntropyLoss как функция потерь.
- Оптимизатор Adam с подобранным learning rate.
- Применялась регуляризация через weight_decay.
- Проводилась оценка метрики accuracy на тренировочной и валидационной выборках (как и требовалось в задании на kaggle).

## 4. Интерпретация результатов
В ходе работы были настроены параметры: количество эпох, скорость обучения, регулиризация.

При большом количестве эпох (более 10) модель показывала признаки переобучения: низкие метрики на валидационных данных и высокие на тренировочных.
Из-за малого размера обучающей выборки при запуске модели на одних и тех же параметрах результаты были всегда сильно различны. Могут быть очень не плохими, а могут быть и ужасными.

Графики зависимости точности и функции потерь от эпох:

Примеры правильных и ошибочных классификаций:



Вывод: модель умеренно справляется с задачей. Результаты можно улучшить увеличив размер обучающей выборки.
