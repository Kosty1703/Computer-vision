# Проект 1: Классификация тарелок (грязные/чистые) с использованием датасета PlatesV2

## 1. Описание задачи и обоснование подхода.
**Цель проекта:** разработка модели компьютерного зрения для классификации изображений тарелок на две категории: «чистая» и «грязная».

**Проблема:** малый объем тренировочных данных.

**Задачи проекта:**
- Сформировать датасет изображений с тарелками.
- Преобразовать изображения для подачи в нейронную сеть.
- Разработать и обучить модель классификации изображений.
- Оценить качество модели на тестовой выборке.
- Визуализировать результаты и проанализировать ошибки.

**Обоснование выбора подхода:** Для решения задачи была выбрана модель на основе свёрточной нейронной сети (CNN), поскольку этот тип архитектур показывает отличные результаты при работе с изображениями. В качестве основы была взята предварительно обученная модель ResNet18, которая дообучалась на сформированном датасете. Это позволило значительно сократить время обучения и добиться допустимой точности на небольшом объеме данных.

## 2. Обоснование выбора методов, инструментов и архитектуры моделей
**Качество предобработки данных:**
- Изображения были приведены к размеру 224x224. На данном размере обучалась выбранная модель ResNet18.
- Применялась нормализация как в ImageNet по среднему и стандартному отклонению каналов (mean, std), соответствующая модели ResNet.
- Для обучения использовалась аугментация: случайные повороты, отражения и изменения яркости и резкости, что повысило обобщающую способность модели.
- Датасеты были переведены в тензоры.

**Разведывательный анализ:**
- Было проведено исследование баланса классов. Классы равны, по 20 изображений в каждом.
- Визуализированы примеры изображений для понимания различий между классами и применения аугментации:
![Аугментация](https://github.com/user-attachments/assets/d0cf89e5-e627-4531-86fd-127d5bb24249)

## 3. Разработка модели и обучение
- Выбрана архитектура ResNet18 — классическая CNN, хорошо работающая с небольшими датасетами при использовании дообучения.
- Последний слой модели был заменён на выход с двумя нейронами, соответствующий бинарной классификации.
- Использовался CrossEntropyLoss как функция потерь.
- Оптимизатор Adam с подобранным learning rate и регуляризацией через weight_decay.
- Выполнена оценка метрики accuracy на тренировочной и валидационной выборках, а также на тестовых данных.

## 4. Интерпретация результатов
В ходе работы были настроены параметры: количество эпох, скорость обучения, регулиризация.

Из-за малого размера обучающей выборки при запуске модели на одних и тех же параметрах результаты были всегда различны. Могли быть не плохими, а могли быть и ужасными. Добавление кросс-валидации незначительно, но улучшило результаты. Разбег результатов accuracy находится в диапазоне от 0,73 до 0,79. Попытки добавления ранней остановки не привели к положительным результатам.
![Результаты](https://github.com/user-attachments/assets/0fb54931-a9c6-4239-82e3-a10d982a6a19)

**Лучший результат среди всех участников соревнования (2400 из 3040):**

![С кросс валидацией](https://github.com/user-attachments/assets/38d8c187-4cf8-4f31-a4fd-ebb18852f3f6)

Есть к чему стремиться.


**Графики зависимости точности и функции потерь от эпох:**
![Графики](https://github.com/user-attachments/assets/fae12cc5-10a1-4c39-b564-c3aede113496)
Из графиков видно, что большое количество эпох не приводит к переобучению при настроенных параметрах модели. Потери снижаются стабильно, но точность меняется скачкообразно, после 40 эпох ужа мало меняется.

**Примеры ошибок:**

<img src="https://github.com/user-attachments/assets/3efb1162-8c26-4a25-8133-e5b60640aa23" width="250" />

**Вывод:** модель умеренно справляется с задачей. При каждом обучении качетсво различно. Результаты можно улучшить увеличив размер обучающей выборки.

*На kaggle не получилось загрузить код, так как не скачивается модель ResNet-18 с весами. Причина: не привязывается номер телефона и поэтому нет интернета на kaggle.*
